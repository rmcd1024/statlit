---
title: 'Statistically Literate Documents: Introduction'
author: "Robert McDonald"
date: '`r format(Sys.Date(), format="%B %d, %Y")`'
output:
  ioslides_presentation:
    incremental: yes
    toc: yes
    transition: faster
  beamer_presentation:
    incremental: yes
  slidy_presentation:
    incremental: yes
bibliography: bib_example.bib
---

```{r setup, include=FALSE}
rm(list=ls())
library(knitr)
library(xtable)
options(digits=5)
knitr::opts_chunk$set(echo = FALSE)
```

## License

<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a><br /><span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Statistically-Literate Documents: Introduction</span> by <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName">Robert L McDonald</span> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.<br />Based on a work at <a xmlns:dct="http://purl.org/dc/terms/" href="https://github.com/rmcd1024/statlit" rel="dct:source">https://github.com/rmcd1024/statlit</a>.

<p><p>

The [source code for this document](https://raw.githubusercontent.com/rmcd1024/statlit/master/litdoc_intro.Rmd) is available on github

# Motivation

## Reproducibility

* The research paradigm presumes honesty and verifiability
    * Data should be made available (if possible)
    * All transformations, omissions, modifications, calculations, etc. should be clearly documented
    * Citations should be complete and accurate
* How would your respond to a scholarly request for details about your work?
* How would you respond to a fraud allegation? 

## Reproducibility is a Habit

* Reproducible research is a _process_, reinforced by work habits
* You want a workflow that is self-documenting and tools that support this
* It is helpful to use research tools that 
    * make it easy for you to retrace your steps
    * make it easy to share your work process with others
    * are robust (e.g. files should still be readable a decade later)
* This talk is about tools


## Goals of this Talk

* Stress the importance of reproducibility
* Provide an example of reproducibility (these slides)
* Provide a roadmap through a particular set of tools
* Put in a plug for those tools
* The important thing is for you to use tools 
    * with which you and coauthors are comfortable
    * that support reproducibility

# Statistical Literacy

## Code and Statistical "Literacy"

* The basic idea of literate documents was developed in the early 1980's by [Donald Knuth](http://www-cs-faculty.stanford.edu/~uno/) in the context of writing and documenting computer programs
* The resurgence of interest has been accompanied by several developments:
    * [Markdown](https://daringfireball.net/projects/markdown/), a simple mark-up syntax
    * [Pandoc](http://pandoc.org/), a document conversion toolkit
    * [Git](https://git-scm.com/), a version control system which makes obvious the benefits of using simple text files
    * The rise of Linux, open source, and cloud-based collaboration


## "Literate" Documents

* "Literate" statistical documents contain both code and text in a single file. 

    * Systems for processing literate documents typically have "web" in the name: "web", "cweb", "noweb", etc.

    * "Weaving" is the process of creating the human-readable document

    * "Tangling" is the process of extracting the code so it can be compiled

* A literate document can contain a complete record of all steps from the processing of raw data to publication.
    * A literate document is by definition "reproducible"

  
## Creating Literate Documents

* Two common paths:
    * [Markdown](https://daringfireball.net/projects/markdown/)/[RMarkdown](http://rmarkdown.rstudio.com/) plus [Pandoc](http://pandoc.org/)
    * LaTeX and R 
* A markdown document is a simple, readable text file that can be processed to yield nicely formatted output
    * These slides are written in Rmarkdown and processed with knitr and pandoc
* Pandoc is a document conversion tool permitting conversion among markdown, HTML, pdf, docx, latex, etc.
* I will demonstrate markdown $\to$ HTML in this talk 
    * The main ideas are the same when using LaTeX and markdown. The chunk  syntax is slightly different.
  
## Tools for Creating Literate Documents

* RStudio includes Pandoc and makes the process easy
* You need not use RStudio; you can use _any_ text editor --- Vim, Emacs, Sublime Text, TextMate, Notepad++, etc.
    * Pick a text editor and learn how to use it.
* You can use  programming languages other than R
    * I will present a python example later
    * You can also do this with [Stata](http://www.ssc.wisc.edu/~hemken/Stataworkshops/Stata%20and%20R%20Markdown/Stata.html) 
* You will be much better off if you are comfortable at the command line
    * If you don't know how to use the command line, learn!

# Examples

## Markdown Example

These are the first few lines of an earlier slide:

```
## Creating Literate Documents

* Two common paths:
    * [Markdown](https://daringfireball.net/projects/markdown/)/[RMarkdown](http://rmarkdown.rstudio.com/) plus [Pandoc](http://pandoc.org/)
    * LaTeX and R 
* A markdown document is a simple, readable text file that can be processed to yield nicely formatted output

```

* Use `##` to create a slide title
* Use `*` and indents to create bullet lists 
* Use `[]()` to create hyperlinks 
 
    
## R 

Existing literate systems can accommodate a wide variety of programming and statistical languages; my examples will use R


* R is free, open source, and extraordinarily capable
* There is much development around R with regard to literate documents (e.g., see [RMarkdown](http://rmarkdown.rstudio.com/))
* RStudio is a natural frontend because it incorporates Pandoc and its developers created Rmarkdown
* The [knitr documentation](http://yihui.name/knitr/demo/engines/) provides sample scripts for Python, SAS, Scala, Haskell, Scala etc.
* The "literate" idea is powerful, general, and scalable


## Example: Simulation 

* Suppose we want to explain quasi-random number generation, and the link between uniform, normal, and lognormal random numbers.

* We draw uniform quasi-random numbers, transform those into normal random numbers, and then transform those into lognormal random numbers.
* We want to 
    * show the code
    * present a table illustrating these transformations
    * present histograms showing the results

## Code Example


```{r randgen, echo=TRUE, eval=TRUE, results='hide'}
n <- 1e04; m <- 6
set.seed(15)      ## make example reproducible
u <- runif(n)     ## generate uniform random variables
z <- qnorm(u)     ## generate normal random variables
y <- exp(z)       ## generate lognormal random variables
kable(cbind('Random Uniform'=u[1:m],    ## create the table
            'Corresponding Normal'=z[1:m], 
            'Implied Lognormal'=y[1:m]))
```

This code generates `r format(n, big.mark=',', scientific=FALSE)` uniform random variables ($u$), which are  converted to normal using the inverse probability transform and then to lognormal: 
$$z = N^{-1}(u)$$
$$y = e^{z}$$


## Elaboration

* Note that the code is vectorized; there are no explicit loops
* `set.seed()` is used to start the random number process at a specified value. 
* `runif()` is R's uniform random number generator. The first value produced is `r u[1]`
* We then run ` `r paste0('qnorm(', format(u[1], digits=8), ')')`` to produce the normal value `r z[1]` (`rnorm()` does this directly)
* Finally, ``r paste0('exp(', format(z[1], digits=8),')')`` produces the lognormal value `r y[1]` (`rlnorm()` does this directly)
* If you look at [the code for this document](https://raw.githubusercontent.com/rmcd1024/statlit/master/litdoc_intro.Rmd) on github, everything is there

## Code

Here are the first `r m` lines of output:

```{r, eval=TRUE, ref.label="randgen"}
```


## Plots

It is helpful to present histograms for each distribution:

```{r randplots, eval=FALSE, echo=TRUE, fig.cap='From uniform to normal to lognormal...'}
par(mfrow=c(2,2))     ## do a 2x2 grid, row priority
## uniform histogram with distribution function
hist(u, main='Uniform', freq=FALSE)   
curve(dunif(x), add=TRUE, col='red')
## normal histogram with distribution function
hist(z, main='Normal', freq=FALSE, ylim=c(0, 0.5))
curve(dnorm(x), add=TRUE, col='red')
## lognormal histogram with distribution function
hist(y, main='Lognormal', ylim=c(0, 0.8), 
     xlim=c(0, 10), breaks=200, freq=FALSE)
curve(dlnorm(x), add=TRUE, col='red')
## qq plot to test for normality of z
qqnorm(z, main='Is z normal?')
```


## The Plots

```{r, ref.label='randplots'}
```

## Python

Rmarkdown also works for python (there is no tab formatting in html output...)

```{python, results='asis', echo=TRUE}
import random
def greet(name):
    print 'Hello ' + name + '\t' + \
    format(random.normalvariate(0, 1)) + '\n'
greet('Jack')
greet('Jill')
greet('Bob')

```


## Data


```{r stkplot, cache=FALSE, echo=TRUE}
dl <- FALSE
if (dl | !file.exists('aapl.csv')) {
    url <- 'http://real-chart.finance.yahoo.com/table.csv?s=AAPL'
    x <- read.csv(url, stringsAsFactors=FALSE)
    write.csv(x, file='aapl.csv')
} else x <- read.csv('aapl.csv', stringsAsFactor=FALSE)
x$Date <- as.Date(x$Date)
x <- x[order(x$Date), ]
x <- x[x$Date >= '2000-1-1', ]
x$ret <- c(NA, diff(log(x$Adj.Close)))
x$year <- as.POSIXlt(x$Date)$year + 1900
vol <- tapply(x$ret, x$year, sd)*sqrt(252)
```

* Presentations can have up-to-date data (latest: `r max(x$Date)`)

* This code downloads Apple data from Yahoo or reads from a file depending on whether `dl` is `TRUE` or `FALSE`

## Analysis of Apple Since 2000

```{r aaplplots, echo=FALSE}
par(mfrow=c(2,2))
plot(x$Date, x$ret, type='l', main="Daily Returns")
plot(x$Date, x$ret^2, type='l', main="Squared Daily Returns")
plot(names(vol), vol, main="Annual Historical Volatility")
qqnorm(x$ret, main="Is Apple Normally Distributed?")
```

## ?

How much code was required to produce the previous page?


## Code for the Plots

5 lines:

```{r, ref.label="aaplplots", eval=FALSE, echo=TRUE}
```

* (In case you're wondering about the outlier in the plots, Apple dropped from $53.50 to $25.75 on September 29, 2000.)

## The point

* The point of these examples is that creating high quality literate documents is no more work than what you are already doing, if you use the right tools
    * Cutting and pasting is _never_ reproducible
* You want to be able to create a zip file that
    * can be extracted and run on someone elses's machine
    * will still be readable and executable 20 years from now
    
    
## Code Chunk Options

* When you add code (in a "chunk"), you can always decide whether to display the code (some or all of it), whether to execute it, whether to display the output, whether the font is large or small, etc.
* You can name chunks and reuse them later
* You can cache chunks, so that time-consuming calculations are saved for re-use later
* You can control the size of graphics
* There are numerous [chunk options](http://yihui.name/knitr/options/)

## Bibliographic references

You can store citation information in bibtex format:

```
@Book{taibbi:11,
  author = 	 {Matt Taibbi},
  title = 	 {Griftopia},
  publisher = 	 {Random House},
  year = 	 2011
}
```

* RMarkdown supports bibliographic references (using pandoc-citeproc)

* This citation: `@taibbi:11`, produces @taibbi:11

* More examples (see bib_example.bib): @mcdonald/paulson:15,
  @wickham:14-ar, @wickham:15-rpkg, and @brennan/mcdonald:15-taxnotes



## Conclusion

* Rmarkdown gives you a tremendously flexible tool for integrating code into your documents
* Code integration gives you reproducibility
* You can incorporate both code and explanations for all calculations,  output, tables, and figures into a single document
* You can decide whether or not to display the underlying code. (You can easily have a version of your document displaying all code, some, or none.)
* RStudio provides great training wheels, and gives you  flexibility to choose your output format


# References

## Bibliography
